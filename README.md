Project Overview

Credit card fraud is a major challenge for the banking and fintech industry. The goal of this project is to build a reliable and interpretable fraud detection system that can:

Accurately identify fraudulent transactions

Minimize financial losses

Reduce false positives to maintain good customer experience

Provide explainable predictions for business trust

This project follows a complete real-world ML workflow, from raw data to a saved production-ready model.

 Dataset Information

Source: Kaggle â€“ Credit Card Fraud Detection Dataset

Observations: 284,807 transactions

Fraud Cases: 492 (â‰ˆ 0.17%)

Features:

V1 to V28 â€“ PCA-transformed features

Time â€“ Seconds elapsed between each transaction

Amount â€“ Transaction amount

Class â€“ Target variable

1 â†’ Fraud

0 â†’ Non-Fraud

âœ… The dataset is extremely imbalanced, making it ideal for real-world fraud modeling.

âš™ï¸ Tools & Technologies Used

Programming Language: Python

Libraries:

pandas, numpy â€“ Data handling

matplotlib, seaborn â€“ Visualization

scikit-learn â€“ ML models & evaluation

imbalanced-learn (SMOTE) â€“ Class imbalance handling

xgboost / GradientBoosting â€“ Advanced ML model

shap â€“ Model explainability

joblib â€“ Model & pipeline saving

ğŸ” Project Workflow

Environment Setup

Data Loading & Inspection

Problem Definition

Exploratory Data Analysis (EDA)

Data Preprocessing

Handling Class Imbalance using:

Class Weighting

SMOTE Oversampling

Model Training:

Logistic Regression

Random Forest

Gradient Boosting / XGBoost

Model Evaluation using:

Confusion Matrix

Precision, Recall, F1-score

ROC-AUC, PR-AUC

Model Comparison & Selection

Feature Importance & Explainability (SHAP & Coefficients)

Threshold Optimization

Final Model Saving & Deployment-ready Predictions

ğŸ“Š Key Evaluation Metrics

Since fraud detection is a high-risk classification problem, the following metrics were prioritized:

âœ… Recall (Most Important) â€“ To minimize missed frauds

âœ… F1-Score â€“ Balance between precision & recall

âœ… ROC-AUC â€“ Overall separability

âœ… PR-AUC â€“ Performance on imbalanced data

âŒ Accuracy alone was not used due to extreme class imbalance.

ğŸ† Best Model Selection

The final model was selected based on:

Highest Recall

Strong F1-score

Best ROC-AUC & PR-AUC

 [Insert your best model name here, e.g., Random Forest / Gradient Boosting] was selected as the final production-ready model.

 Model Explainability

Feature Importance from tree-based models

Logistic Regression coefficients

SHAP explainability was attempted:

PCA-transformed features and pipelines caused compatibility limitations

Model interpretation was successfully handled using traditional techniques
